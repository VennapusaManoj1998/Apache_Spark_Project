{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c56a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Py Spark using MLib on Classificatio of flower using sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5337b0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
      "  Obtaining dependency information for py4j==0.10.9.7 from https://files.pythonhosted.org/packages/10/30/a58b32568f1623aaad7db22aa9eafc4c6c194b429ff35bdc55ca2726da47/py4j-0.10.9.7-py2.py3-none-any.whl.metadata\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425347 sha256=15f8b0d5daa82ebcd9140c4a7359ab05368c8e7306cc18f047aec8aa6d061cb4\n",
      "  Stored in directory: /Users/manoj/Library/Caches/pip/wheels/38/df/61/8c121f50c3cffd77f8178180dd232d90b3b99d1bd61fb6d6be\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a10be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "spark = SparkSession.builder.appName('mllib').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505ff99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.13.11.51:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>mllib</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11032be10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 13:03:48 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a66af450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Users/manoj/Desktop/Spark/bezdekIris_data.csv\", inferSchema=True).toDF(\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2c1aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-----------+\n",
      "|sep_len|sep_wid|pet_len|pet_wid|      label|\n",
      "+-------+-------+-------+-------+-----------+\n",
      "|    5.1|    3.5|    1.4|    0.2|Iris-setosa|\n",
      "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|\n",
      "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|\n",
      "|    4.6|    3.1|    1.5|    0.2|Iris-setosa|\n",
      "|    5.0|    3.6|    1.4|    0.2|Iris-setosa|\n",
      "|    5.4|    3.9|    1.7|    0.4|Iris-setosa|\n",
      "|    4.6|    3.4|    1.4|    0.3|Iris-setosa|\n",
      "|    5.0|    3.4|    1.5|    0.2|Iris-setosa|\n",
      "|    4.4|    2.9|    1.4|    0.2|Iris-setosa|\n",
      "|    4.9|    3.1|    1.5|    0.1|Iris-setosa|\n",
      "|    5.4|    3.7|    1.5|    0.2|Iris-setosa|\n",
      "|    4.8|    3.4|    1.6|    0.2|Iris-setosa|\n",
      "|    4.8|    3.0|    1.4|    0.1|Iris-setosa|\n",
      "|    4.3|    3.0|    1.1|    0.1|Iris-setosa|\n",
      "|    5.8|    4.0|    1.2|    0.2|Iris-setosa|\n",
      "|    5.7|    4.4|    1.5|    0.4|Iris-setosa|\n",
      "|    5.4|    3.9|    1.3|    0.4|Iris-setosa|\n",
      "|    5.1|    3.5|    1.4|    0.3|Iris-setosa|\n",
      "|    5.7|    3.8|    1.7|    0.3|Iris-setosa|\n",
      "|    5.1|    3.8|    1.5|    0.3|Iris-setosa|\n",
      "+-------+-------+-------+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18461eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sep_len: double (nullable = true)\n",
      " |-- sep_wid: double (nullable = true)\n",
      " |-- pet_len: double (nullable = true)\n",
      " |-- pet_wid: double (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69140080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+------------------+-----------------+----------+\n",
      "|     avg(sep_len)|     avg(sep_wid)|      avg(pet_len)|     avg(pet_wid)|avg(label)|\n",
      "+-----------------+-----------------+------------------+-----------------+----------+\n",
      "|5.843333333333335|3.057333333333334|3.7580000000000027|1.199333333333334|      NULL|\n",
      "+-----------------+-----------------+------------------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "df.select(*[mean(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14821e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-----------+-----------------+\n",
      "|sep_len|sep_wid|pet_len|pet_wid|      label|         features|\n",
      "+-------+-------+-------+-------+-----------+-----------------+\n",
      "|    5.1|    3.5|    1.4|    0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "+-------+-------+-------+-------+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_assembler = VectorAssembler(inputCols=[\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\"], outputCol=\"features\")\n",
    "df_temp = vector_assembler.transform(df)\n",
    "df_temp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe458dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|      label|         features|\n",
      "+-----------+-----------------+\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_temp.drop('sep_len', 'sep_wid', 'pet_len', 'pet_wid')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21de38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\" )\n",
    "df = l_indexer.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f0199ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+\n",
      "|      label|         features|labelIndex|\n",
      "+-----------+-----------------+----------+\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.2]|       0.0|\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|       0.0|\n",
      "|Iris-setosa|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "+-----------+-----------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22cac33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50c527a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"labelIndex\", featuresCol=\"features\")\n",
    "model = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6ef721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07e5ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9555555555555556\n",
      "Test Error = 0.0444444 \n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\\\n",
    "labelCol=\"labelIndex\", predictionCol=\"prediction\",\\\n",
    "metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bias Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8469dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3bbb277",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(labelCol=\"labelIndex\",\\\n",
    "featuresCol=\"features\", smoothing=1.0,\\\n",
    "modelType=\"multinomial\")\n",
    "model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ecc5e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+----------+\n",
      "|      label|labelIndex|         probability|prediction|\n",
      "+-----------+----------+--------------------+----------+\n",
      "|Iris-setosa|       0.0|[0.73502886090153...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.64985557718392...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.55508830217120...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.71765512033989...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.66081341393231...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.64974667051749...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.74441220910135...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.64883669266108...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.73798193287052...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.59910017548780...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.76033164161201...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.72728619556167...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.72713552086094...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.70836433322158...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.74686759626570...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.75800913997892...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.74584676369177...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.76824596749676...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.70895817628638...|       0.0|\n",
      "|Iris-setosa|       0.0|[0.78099728534983...|       0.0|\n",
      "+-----------+----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 13:49:35 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/02/25 13:49:35 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.select(\"label\", \"labelIndex\",\n",
    "\"probability\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fedebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9682539682539683\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy:\", str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9dd611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
